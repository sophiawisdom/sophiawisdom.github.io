<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>Sophia Wisdom's Blog</title><meta name=viewport content="width=device-width,minimum-scale=1"><meta name=description content="A friend of mine was desperate &ndash; just desperate &ndash; for speedy kernels. She knew the math, she knew the ML, she knew what had to be done. But her kernels were ludicrously slow because she didn&rsquo;t understand the GPU. The GPU is a fundamentally different machine than the CPU, with fundamentally different capabilities, especially with the rise of Tensor Cores and other fixed-function &ldquo;accelerators within the accelerator&rdquo;. It is difficult to predict and understand what math operations can be made to run quickly on the GPU and why."><meta name=generator content="Hugo 0.110.0"><meta name=robots content="noindex, nofollow"><link rel=stylesheet href=/ananke/css/main.min.css><meta property="og:title" content><meta property="og:description" content="A friend of mine was desperate &ndash; just desperate &ndash; for speedy kernels. She knew the math, she knew the ML, she knew what had to be done. But her kernels were ludicrously slow because she didn&rsquo;t understand the GPU. The GPU is a fundamentally different machine than the CPU, with fundamentally different capabilities, especially with the rise of Tensor Cores and other fixed-function &ldquo;accelerators within the accelerator&rdquo;. It is difficult to predict and understand what math operations can be made to run quickly on the GPU and why."><meta property="og:type" content="article"><meta property="og:url" content="https://sophiawisdom.github.io/posts/ssm/"><meta property="article:section" content="posts"><meta itemprop=name content><meta itemprop=description content="A friend of mine was desperate &ndash; just desperate &ndash; for speedy kernels. She knew the math, she knew the ML, she knew what had to be done. But her kernels were ludicrously slow because she didn&rsquo;t understand the GPU. The GPU is a fundamentally different machine than the CPU, with fundamentally different capabilities, especially with the rise of Tensor Cores and other fixed-function &ldquo;accelerators within the accelerator&rdquo;. It is difficult to predict and understand what math operations can be made to run quickly on the GPU and why."><meta itemprop=wordCount content="626"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content><meta name=twitter:description content="A friend of mine was desperate &ndash; just desperate &ndash; for speedy kernels. She knew the math, she knew the ML, she knew what had to be done. But her kernels were ludicrously slow because she didn&rsquo;t understand the GPU. The GPU is a fundamentally different machine than the CPU, with fundamentally different capabilities, especially with the rise of Tensor Cores and other fixed-function &ldquo;accelerators within the accelerator&rdquo;. It is difficult to predict and understand what math operations can be made to run quickly on the GPU and why."></head><body class="ma0 avenir bg-near-white"><header><div class=bg-black><nav class="pv3 ph3 ph4-ns" role=navigation><div class="flex-l justify-between items-center center"><a href=/ class="f3 fw2 hover-white no-underline white-90 dib">Sophia Wisdom's Blog</a><div class="flex-l items-center"><div class=ananke-socials></div></div></div></nav></div></header><main class=pb7 role=main><article class="flex-l flex-wrap justify-between mw8 center ph3"><header class="mt4 w-100"><aside class="instapaper_ignoref b helvetica tracked">POSTS</aside><div id=sharing class="mt3 ananke-socials"></div><h1 class="f1 athelas mt3 mb1"></h1></header><div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><p>A friend of mine was desperate &ndash; just desperate &ndash; for speedy kernels. She knew the math, she knew the ML, she knew what had to be done. But her kernels were ludicrously slow because she didn&rsquo;t understand the GPU. The GPU is a fundamentally different machine than the CPU, with fundamentally different capabilities, especially with the rise of Tensor Cores and other fixed-function &ldquo;accelerators within the accelerator&rdquo;. It is difficult to predict and understand what math operations can be made to run quickly on the GPU and why.</p><h2 id=why-are-gpus-such-a-big-deal-anyway>Why are GPUs such a big deal anyway?</h2><p>The GPU is an accelerator. Its purpose is to make certain computations faster. It does not make most code faster. The vast majority of programs are written for CPUs, and programs written for GPUs are core &ldquo;inner loop&rdquo; algorithms that must be very fast. If you compare kernels written for the GPU to, say, React frontend code, you write ~100x less code and spend ~1000x as much time running that code. Production Transformer models are a few thousand lines of CUDA that are run for millions of GPU-hours. When you&rsquo;ve been reduced to the point of writing a GPU kernel, you have a desparate need for performance that cannot be slaked by writing the equivalent of Python, so even &ldquo;<a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/#cuda-a-general-purpose-parallel-computing-platform-and-programming-model#high-level%20programming%20language:~:text=C%2B%2B%20as%20a-,high%2Dlevel%20programming%20language,-.%20As%20illustrated%20by">high level</a>&rdquo; programming languages require a solid understanding of the hardware to achieve acceptable performance.</p><p>Because performance analysis on GPUs requires a solid understanding of a somewhat weird machine, I&rsquo;m going to explain the hardware at the same time as the software.</p><p>What do GPUs accelerate? Originally graphics (<em>Graphics</em> Processing Unit) but now just any highly parallel code. There are a few tricks they use to be better at this than CPUs. The main one is that they do away with a lot of things that are not directly related to floating point computation: less <a href=https://en.wikipedia.org/wiki/CPU_cache>cache</a>, less <a href=https://en.wikipedia.org/wiki/Out-of-order_execution>OOO</a>, no <a href=https://en.wikipedia.org/wiki/Register_renaming>register renaming</a>, etc. These features are valuable, and sequential code executes less quickly for their absence. What do you get for this sacrifice? Well the AMD EPYC 9654 has the same number of transistors as the RTX 4090<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> and costs about ten times as much money<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup> but the RTX 4090 can do ~80 float32 TFLOP/s where the EPYC 9654 can do ~10 float32 TFLOP/s[^3].</p><p>The A100 is divided into many different Streaming Multiprocessors (SMs), each with their own very fast memory called &ldquo;shared memory&rdquo; and four Streaming Multiprocessor SubProcessors (SMSPs) which can be thought of for our purposes as 1024 bit wide vector cores (i.e. they do 32 32-bit floating point operations at a time instead of 1 at a time) with Tensor Cores (explained later) and their own registers. They are <a href=https://en.wikipedia.org/wiki/Barrel_processor>barrel processors</a>, which can be thought of as if Hyperthreading with up to 64 threads.</p><p>The most important things to know about the GPU and ML are that 1) <a href=https://twitter.com/jekbradbury>flops are learning</a> 2) all (85%) of the flops are in the Tensor Cores.</p><p><img src=./h100.png alt="opinionated h100 datasheet"></p><p>knew the math, but she &ndash; like many in these parts &ndash; did not understand the GPU (cardinal sin!). So she was reduced to begging me for some way to make her architecture fast.</p><p>GPUs are designed for parallel processing, whereas CPUs are designed for sequential processing<sup id=fnref1:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>. Modern ML is extremely parallel<sup id=fnref1:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>. Great fit! What does it even mean to be designed for parallel processing? How specifically are they designed?</p><p>And lo! I made it fast. But how?</p><p>She begged me: Sophia, please come in, and make my kernels fast, and then write a blog post later on as a form of resume. An</p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>78 billion for AMD EPYC 9654, 76 billion for RTX 4090. It&rsquo;s also <em>way</em> more expensive &ndash; $11,000 for 9654, $1,500 for 4090.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref1:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>Likely in part <a href=https://arxiv.org/abs/2009.06489>because it was created on GPUs</a>!&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref1:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div><ul class=pa0></ul><div class="mt6 instapaper_ignoref"></div></div><aside class="w-30-l mt6-l"></aside></article></main><footer class="bg-black bottom-0 w-100 pa3" role=contentinfo><div class="flex justify-between"><a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href=https://sophiawisdom.github.io/>&copy; Sophia Wisdom's Blog 2023</a><div><div class=ananke-socials></div></div></div></footer></body></html>